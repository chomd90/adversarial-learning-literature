# Adversarial learning literature :
This repo is an attempt to catalog and keep track of publications in the field of Adversarial Machine Learning. This includes Adversarial Attacks, Defences, Robustness Verification and Analysis.

## ICML 2019
1. [Adversarial Attacks on Node Embeddings via Graph Poisoning](http://proceedings.mlr.press/v97/bojchevski19a/bojchevski19a.pdf)
1. [First-order Adversarial Vulnerability of Neural Networks and Input Dimension](http://proceedings.mlr.press/v97/simon-gabriel19a/simon-gabriel19a.pdf)
1. [On Certifying Non-uniform Bounds against Adversarial Attacks](http://proceedings.mlr.press/v97/liu19h/liu19h.pdf)
1. [Improving Adversarial Robustness via Promoting Ensemble Diversity](http://proceedings.mlr.press/v97/pang19a/pang19a.pdf)
1. [Adversarial camera stickers: A physical camera-based attack on deep learning systems](http://proceedings.mlr.press/v97/li19j/li19j.pdf)
1. [Adversarial examples from computational constraints](http://proceedings.mlr.press/v97/bubeck19a/bubeck19a.pdf)
1. [POPQORN: Quantifying Robustness of Recurrent Neural Networks](http://proceedings.mlr.press/v97/ko19a/ko19a.pdf)
1. [Using Pre-Training Can Improve Model Robustness and Uncertainty](http://proceedings.mlr.press/v97/hendrycks19a/hendrycks19a.pdf)
1. [Limitations of Adversarial Robustness: Strong No Free Lunch Theorem](http://proceedings.mlr.press/v97/dohmatob19a/dohmatob19a.pdf)
1. [PROVEN: Verifying Robustness of Neural Networks with a Probabilistic Approach](http://proceedings.mlr.press/v97/weng19a/weng19a.pdf)
1. [Robust Decision Trees Against Adversarial Examples](http://proceedings.mlr.press/v97/chen19m/chen19m.pdf)
1. [Rademacher Complexity for Adversarially Robust Generalization](http://proceedings.mlr.press/v97/yin19b/yin19b.pdf)
1. [Are Generative Classifiers More Robust to Adversarial Attacks?](http://proceedings.mlr.press/v97/li19a/li19a.pdf)
1. [Theoretically Principled Trade-off between Robustness and Accuracy](http://proceedings.mlr.press/v97/zhang19p/zhang19p.pdf)
1. [The Odds are Odd: A Statistical Test for Detecting Adversarial Examples](http://proceedings.mlr.press/v97/roth19a/roth19a.pdf)
1. [ME-Net: Towards Effective Adversarial Robustness with Matrix Estimation](http://proceedings.mlr.press/v97/yang19e/yang19e.pdf)
1. [Certified Adversarial Robustness via Randomized Smoothing](http://proceedings.mlr.press/v97/cohen19c/cohen19c.pdf)
1. [Imperceptible, Robust, and Targeted Adversarial Examples for Automatic Speech Recognition](http://proceedings.mlr.press/v97/qin19a/qin19a.pdf)
1. [Parsimonious Black-Box Adversarial Attacks via Efficient Combinatorial Optimization](http://proceedings.mlr.press/v97/moon19a/moon19a.pdf)
1. [Wasserstein Adversarial Examples via Projected Sinkhorn Iterations](http://proceedings.mlr.press/v97/wong19a/wong19a.pdf)
1. [NATTACK: Learning the Distributions of Adversarial Examples for an Improved Black-Box Attack on Deep Neural Networks](http://proceedings.mlr.press/v97/li19g/li19g.pdf)
1. [Simple Black-box Adversarial Attacks](http://proceedings.mlr.press/v97/guo19a/guo19a.pdf)
1. [Adversarial Examples Are a Natural Consequence of Test Error in Noise](http://proceedings.mlr.press/v97/gilmer19a/gilmer19a.pdf)
1. [Exploring the Landscape of Spatial Robustness](http://proceedings.mlr.press/v97/engstrom19a/engstrom19a.pdf)
1. [Interpreting Adversarially Trained Convolutional Neural Networks](http://proceedings.mlr.press/v97/zhang19s/zhang19s.pdf)
1. [On the Convergence and Robustness of Adversarial Training](http://proceedings.mlr.press/v97/wang19i/wang19i.pdf)
1. [On the Connection Between Adversarial Robustness and Saliency Map Interpretability](http://proceedings.mlr.press/v97/etmann19a/etmann19a.pdf)

## ICLR 2019 :
**Attacks**
1. [Adversarial Attacks on Graph Neural Networks via Meta Learning](https://openreview.net/forum?id=Bylnx209YX)
1. [Prior Convictions: Black-box Adversarial Attacks with Bandits and Priors](https://openreview.net/forum?id=BkMiWhR5K7)
1. [Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically Differentiable Renderer](https://openreview.net/forum?id=SJl2niR9KQ)
1. [ADef: an Iterative Algorithm to Construct Adversarial Deformations](https://openreview.net/forum?id=Hk4dFjR5K7)
1. [Structured Adversarial Attack: Towards General Implementation and Better Interpretability](https://openreview.net/forum?id=BkgzniCqY7)
1. [The Limitations of Adversarial Training and the Blind-Spot Attack](https://openreview.net/forum?id=HylTBhA5tQ)
1. [CAMOU: Learning Physical Vehicle Camouflages to Adversarially Attack Detectors in the Wild](https://openreview.net/forum?id=SJgEl3A5tm)

**Defences**
1. [Cost-Sensitive Robustness against Adversarial Examples](https://openreview.net/forum?id=BygANhA9tQ)
1. [Generalizable Adversarial Training via Spectral Normalization](https://openreview.net/forum?id=Hyx4knR9Ym)
1. [Towards the first adversarially robust neural network model on MNIST](https://openreview.net/forum?id=S1EHOsC9tX)
1. [PeerNets: Exploiting Peer Wisdom Against Adversarial Attacks](https://openreview.net/forum?id=Sk4jFoA9K7)
1. [Characterizing Audio Adversarial Examples Using Temporal Dependency](https://openreview.net/forum?id=r1g4E3C9t7)
1. [Improving the Generalization of Adversarial Training with Domain Adaptation](https://openreview.net/forum?id=SyfIfnC5Ym)
1. [Adv-BNN: Improved Adversarial Defense through Robust Bayesian Neural Network](https://openreview.net/forum?id=rk4Qso0cKm)
1. [Adversarial Reprogramming of Neural Networks](https://openreview.net/forum?id=Syx_Ss05tm)
1. [Defensive Quantization: When Efficiency Meets Robustness](https://openreview.net/forum?id=ryetZ20ctX)

**Verification**
1. [Rigorous Agent Evaluation: An Adversarial Approach to Uncover Catastrophic Failures](https://openreview.net/forum?id=B1xhQhRcK7)
1. [Training for Faster Adversarial Robustness Verification via Inducing ReLU Stability](https://openreview.net/forum?id=BJfIVjAcKm)
1. [Benchmarking Neural Network Robustness to Common Corruptions and Perturbations](https://openreview.net/forum?id=HJz6tiCqYm)
1. [Evaluating Robustness of Neural Networks with Mixed Integer Programming](https://openreview.net/forum?id=HyGIdiRqtm)
1. [A Statistical Approach to Assessing Neural Network Robustness](https://openreview.net/forum?id=S1xcx3C5FX)
1. [Robustness Certification with Refinement](https://openreview.net/forum?id=HJgeEh09KQ)

**Analysis**
1. [Excessive Invariance Causes Adversarial Vulnerability](https://openreview.net/forum?id=BkfbpsAcF7)
1. [On the Sensitivity of Adversarial Robustness to Input Data Distributions](https://openreview.net/forum?id=S1xNEhR9KX)
1. [Robustness May Be at Odds with Accuracy](https://openreview.net/forum?id=SyxAb30cY7)
1. [Are adversarial examples inevitable?](https://openreview.net/forum?id=r1lWUoA9FQ)

## NIPS 2018 :
**Attacks**
1. [Adversarial Examples that Fool both Computer Vision and Time-Limited Humans](http://papers.nips.cc/paper/7647-adversarial-examples-that-fool-both-computer-vision-and-time-limited-humans)
1. [Adversarial Attacks on Stochastic Bandits](http://papers.nips.cc/paper/7622-adversarial-attacks-on-stochastic-bandits)
1. [Constructing Unrestricted Adversarial Examples with Generative Models](http://papers.nips.cc/paper/8052-constructing-unrestricted-adversarial-examples-with-generative-models)

**Defences**
1. [Deep Defense: Training DNNs with Improved Adversarial Robustness](http://papers.nips.cc/paper/7324-deep-defense-training-dnns-with-improved-adversarial-robustness)
1. [Scaling provable adversarial defenses](http://papers.nips.cc/paper/8060-scaling-provable-adversarial-defenses)
1. [Thwarting Adversarial Examples: An L_0-Robust Sparse Fourier Transform](http://papers.nips.cc/paper/8211-thwarting-adversarial-examples-an-l_0-robust-sparse-fourier-transform)
1. [Bayesian Adversarial Learning](http://papers.nips.cc/paper/7921-bayesian-adversarial-learning)
1. [Towards Robust Detection of Adversarial Examples](http://papers.nips.cc/paper/7709-towards-robust-detection-of-adversarial-examples)
1. [Attacks Meet Interpretability: Attribute-steered Detection of Adversarial Samples](http://papers.nips.cc/paper/7998-attacks-meet-interpretability-attribute-steered-detection-of-adversarial-samples)
1. [Robust Detection of Adversarial Attacks by Modeling the Intrinsic Properties of Deep Neural Networks](http://papers.nips.cc/paper/8016-robust-detection-of-adversarial-attacks-by-modeling-the-intrinsic-properties-of-deep-neural-networks)
1. [A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks](http://papers.nips.cc/paper/7947-a-simple-unified-framework-for-detecting-out-of-distribution-samples-and-adversarial-attacks)

**Verification**
1. [Semidefinite relaxations for certifying robustness to adversarial examples](http://papers.nips.cc/paper/8285-semidefinite-relaxations-for-certifying-robustness-to-adversarial-examples)

**Analysis**
1. [Adversarially Robust Generalization Requires More Data](http://papers.nips.cc/paper/7749-adversarially-robust-generalization-requires-more-data)
1. [A Spectral View of Adversarially Robust Features](http://papers.nips.cc/paper/8217-a-spectral-view-of-adversarially-robust-features)
1. [Adversarial vulnerability for any classifier](http://papers.nips.cc/paper/7394-adversarial-vulnerability-for-any-classifier)
1. [Adversarial Risk and Robustness: General Definitions and Implications for the Uniform Distribution](http://papers.nips.cc/paper/8237-adversarial-risk-and-robustness-general-definitions-and-implications-for-the-uniform-distribution)

## ICML 2018 :
**Attacks**
1. [Synthesizing Robust Adversarial Examples](http://proceedings.mlr.press/v80/athalye18b.html)
1. [Adversarial Risk and the Dangers of Evaluating Against Weak Attacks](http://proceedings.mlr.press/v80/uesato18a.html)
1. [Black-box Adversarial Attacks with Limited Queries and Information](http://proceedings.mlr.press/v80/ilyas18a.html)
1. [Adversarial Attack on Graph Structured Data](http://proceedings.mlr.press/v80/dai18b.html)
1. [Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples](http://proceedings.mlr.press/v80/athalye18a.html)
1. [LaVAN: Localized and Visible Adversarial Noise](http://proceedings.mlr.press/v80/karmon18a.html)

**Defences**
1. [Provable Defenses against Adversarial Examples via the Convex Outer Adversarial Polytope](http://proceedings.mlr.press/v80/wong18a.html)
1. [Reinforcing Adversarial Robustness using Model Confidence Induced by Adversarial Training](http://proceedings.mlr.press/v80/wu18e.html)
1. [Differentiable Abstract Interpretation for Provably Robust Neural Networks](http://proceedings.mlr.press/v80/mirman18b.html)

**Verification**
1. [Towards Fast Computation of Certified Robustness for ReLU Networks](http://proceedings.mlr.press/v80/weng18a.html)

**Analysis**
1. [Adversarial Regression with Multiple Learners](http://proceedings.mlr.press/v80/tong18a.html)
1. [Learning Adversarially Fair and Transferable Representations](http://proceedings.mlr.press/v80/madras18a.html)
1. [Analyzing the Robustness of Nearest Neighbors to Adversarial Examples](http://proceedings.mlr.press/v80/wang18c.html)

## ICLR 2018 :
**Attacks**
1. [Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models](https://openreview.net/forum?id=SyZI0GWCZ)
1. [Generating Natural Adversarial Examples](https://openreview.net/forum?id=H1BLjgZCb)
1. [Spatially Transformed Adversarial Examples](https://openreview.net/forum?id=HyydRMZC-)

**Defences**
1. [Towards Deep Learning Models Resistant to Adversarial Attacks](https://openreview.net/forum?id=rJzIBfZAb)
1. [Countering Adversarial Images using Input Transformations](https://openreview.net/forum?id=SyJ7ClWCb)
1. [PixelDefend: Leveraging Generative Models to Understand and Defend against Adversarial Examples](https://openreview.net/forum?id=rJUYGxbCW)
1. [Stochastic Activation Pruning for Robust Adversarial Defense](https://openreview.net/forum?id=H1uR4GZRZ)
1. [Thermometer Encoding: One Hot Way To Resist Adversarial Examples](https://openreview.net/forum?id=S18Su--CW)
1. [Certified Defenses against Adversarial Examples](https://openreview.net/forum?id=Bys4ob-Rb)
1. [Defense-GAN: Protecting Classifiers Against Adversarial Attacks Using Generative Models](https://openreview.net/forum?id=BkJ3ibb0-)
1. [Ensemble Adversarial Training: Attacks and Defenses](https://openreview.net/forum?id=rkZvSe-RZ)
1. [Mitigating Adversarial Effects Through Randomization](https://openreview.net/forum?id=Sk9yuql0Z)
1. [Certifying Some Distributional Robustness with Principled Adversarial Training](https://openreview.net/forum?id=Hk6kPgZA-)

**Analysis**
1. [Decision Boundary Analysis of Adversarial Examples](https://openreview.net/forum?id=BkpiPMbA-)
1. [Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality](https://openreview.net/forum?id=B1gJ1L2aW)

## NIPS 2017 :
1. [Houdini: Fooling Deep Structured Visual and Speech Recognition Models with Adversarial Examples](http://papers.nips.cc/paper/7273-houdini-fooling-deep-structured-visual-and-speech-recognition-models-with-adversarial-examples)
1. [Formal Guarantees on the Robustness of a Classifier against Adversarial Manipulation](http://papers.nips.cc/paper/6821-formal-guarantees-on-the-robustness-of-a-classifier-against-adversarial-manipulation)
1. [Lower bounds on the robustness to adversarial perturbations](http://papers.nips.cc/paper/6682-lower-bounds-on-the-robustness-to-adversarial-perturbations)

## ICML 2017
1. [Parseval Networks: Improving Robustness to Adversarial Examples](http://proceedings.mlr.press/v70/cisse17a.html)

## ICLR 2017
**Attacks**
1. [Tactics of Adversarial Attack on Deep Reinforcement Learning Agents](https://openreview.net/forum?id=r1Cy5yrKx)

**Defences**
1. [Adversarial Machine Learning at Scale](https://openreview.net/forum?id=BJm4T4Kgx)
1. [DeepCloak: Masking Deep Neural Network Models for Robustness Against Adversarial Samples](https://openreview.net/forum?id=r1X_kR4Yl)
1. [Adversarial Training Methods for Semi-Supervised Text Classification](https://openreview.net/forum?id=r1X3g2_xl)
1. [Early Methods for Detecting Adversarial Images](https://openreview.net/forum?id=B1dexpDug)
1. [Robustness to Adversarial Examples through an Ensemble of Specialists](https://openreview.net/forum?id=S1cYxlSFx)

**Analysis**
1. [Delving into adversarial attacks on deep policies](https://openreview.net/forum?id=BJcib5mFe)

## NIPS 2016 :
1. [Robustness of classifiers: from adversarial to random noise](http://papers.nips.cc/paper/6331-robustness-of-classifiers-from-adversarial-to-random-noise)
1. [Measuring Neural Net Robustness with Constraints](http://papers.nips.cc/paper/6339-measuring-neural-net-robustness-with-constraints)

## ICLR 2016 :
1. [Distributional Smoothing with Virtual Adversarial Training](https://arxiv.org/abs/1507.00677)
2. [Adversarial Manipulation of Deep Representations](https://arxiv.org/abs/1511.05122)

## ICLR 2015 :
1. [Explaining and Harnessing Adversarial Examples](http://arxiv.org/abs/1412.6572)
2. [Towards Deep Neural Network Architectures Robust to Adversarial Examples](http://arxiv.org/abs/1412.5068)

## NIPS 2014 :
1. [Feature Cross-Substitution in Adversarial Classification](http://papers.nips.cc/paper/5510-feature-cross-substitution-in-adversarial-classification)

## ICLR 2014 :

1. [Intriguing properties of neural networks](https://openreview.net/forum?id=kklr_MTHMRQjG)
